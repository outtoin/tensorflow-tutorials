{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "W_hist = tf.summary.histogram(\"weight\", W)\n",
    "b_hist = tf.summary.histogram(\"bias\", b)\n",
    "\n",
    "logits = tf.matmul(X, W) + b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                labels=Y)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "acc_summ = tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 \tcost =  2.749032 \taccuracy : 0.730000019\n",
      "Epoch:  0011 \tcost =  0.525497 \taccuracy : 0.889999986\n",
      "Epoch:  0021 \tcost =  0.424241 \taccuracy : 0.970000029\n",
      "Epoch:  0031 \tcost =  0.377266 \taccuracy : 0.870000005\n",
      "Epoch:  0041 \tcost =  0.348691 \taccuracy : 0.949999988\n",
      "Epoch:  0051 \tcost =  0.328876 \taccuracy : 0.910000026\n",
      "Epoch:  0061 \tcost =  0.314175 \taccuracy : 0.949999988\n",
      "Epoch:  0071 \tcost =  0.302689 \taccuracy : 0.939999998\n",
      "Epoch:  0081 \tcost =  0.293930 \taccuracy : 0.879999995\n",
      "Epoch:  0091 \tcost =  0.286744 \taccuracy : 0.879999995\n",
      "Epoch:  0101 \tcost =  0.280727 \taccuracy : 0.970000029\n",
      "Epoch:  0111 \tcost =  0.275594 \taccuracy : 0.920000017\n",
      "Epoch:  0121 \tcost =  0.271332 \taccuracy : 0.939999998\n",
      "Epoch:  0131 \tcost =  0.267481 \taccuracy : 0.939999998\n",
      "Epoch:  0141 \tcost =  0.264232 \taccuracy : 0.920000017\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 150\n",
    "batch_size = 100\n",
    "\n",
    "writer = tf.summary.FileWriter('./logs/MNIST_ML')\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "writer.add_graph(sess.graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# tf.reset_default_graph()\n",
    "summary = tf.summary.merge([cost_summ, w_hist,])\n",
    "\n",
    "global_step = 1\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        xs, ys = mnist.train.next_batch(batch_size)\n",
    "        c, a, s, _ = sess.run([cost, accuracy, summary, optimizer], feed_dict={X: xs, Y: ys})\n",
    "        avg_cost += c / total_batch\n",
    "        writer.add_summary(s, global_step=global_step)\n",
    "        global_step += 1\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: ', '%04d' % (epoch + 1), '\\tcost = ', '{:.6f}'.format(avg_cost), '\\taccuracy :', '{:.9f}'.format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9207\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy.eval(session=sess,\n",
    "                                 feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [6]\n",
      "Prediction:  [6]\n",
      "Result:  [ True]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1186abfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1),\n",
    "                              feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "print(\"Result: \", sess.run(tf.equal(sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)), sess.run(tf.argmax(hypothesis, 1),\n",
    "                              feed_dict={X: mnist.test.images[r:r+1]}))))\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "neurons = 10\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, neurons]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([neurons]), name='bias1')\n",
    "logits1 = tf.matmul(X, W1) + b1\n",
    "layer1 = tf.nn.softmax(logits1)\n",
    "\n",
    "W1_hist = tf.summary.histogram(\"W1\", W1)\n",
    "b1_hist = tf.summary.histogram(\"b1\", b1)\n",
    "layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([neurons]), name='bias3')\n",
    "logits2 = tf.matmul(layer1, W2) + b2\n",
    "layer2 = tf.nn.softmax(logits2)\n",
    "\n",
    "W2_hist = tf.summary.histogram(\"W2\", W2)\n",
    "b2_hist = tf.summary.histogram(\"b2\", b2)\n",
    "layer2_hist = tf.summary.histogram(\"layer2\", layer2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([neurons]), name='bias3')\n",
    "logits3 = tf.matmul(layer2, W3) + b3\n",
    "layer3 = tf.nn.softmax(logits3)\n",
    "\n",
    "W1_hist = tf.summary.histogram(\"W3\", W3)\n",
    "b1_hist = tf.summary.histogram(\"b3\", b3)\n",
    "layer1_hist = tf.summary.histogram(\"layer3\", layer3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([neurons, nb_classes]), name='weight4')\n",
    "b4 = tf.Variable(tf.random_normal([nb_classes]), name='bias4')\n",
    "\n",
    "logits4 = tf.matmul(layer3, W4) + b4\n",
    "hypothesis = tf.nn.softmax(logits4)\n",
    "\n",
    "W4_hist = tf.summary.histogram(\"W4\", W4)\n",
    "b4_hist = tf.summary.histogram(\"b4\", b4)\n",
    "hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits4, \n",
    "                                                labels=Y)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 \tcost =  2.529995067\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-98d0e0438b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_epochs = 150\n",
    "batch_size = 100\n",
    "\n",
    "merge()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        avg_cost += c / total_batch\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: ', '%04d' % (epoch + 1), '\\tcost = ', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.488\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy.eval(session=sess,\n",
    "                                 feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [3]\n",
      "Prediction:  [3]\n",
      "Result:  [ True]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADndJREFUeJzt3X+MVfWZx/HPA4JGIIoySyYUHLaZGA3JwuYGV5do1W1j\nTQ02UVJiNmyCBZOaSFKjxCpV/1HM1to/NpCpkoLp2m5SDMTobl1cnCUqeCEWtegKZvg5MkOoQWIi\nAs/+MYdm1Lnfc7m/zp153q9kMvee55x7Hm74zLn3fO89X3N3AYhnXNENACgG4QeCIvxAUIQfCIrw\nA0ERfiAowg8ERfiBoAg/ENQFrdzZtGnTvKurq5W7BELp6+vTsWPHrJp16wq/md0i6VeSxkt61t2f\nTK3f1dWlcrlczy4BJJRKparXrfllv5mNl/Rvkr4v6WpJi83s6lofD0Br1fOef76kve7+sbufkvQ7\nSQsb0xaAZqsn/DMkHRx2/1C27CvMbJmZlc2sPDg4WMfuADRS08/2u3uPu5fcvdTR0dHs3QGoUj3h\nPyxp5rD738qWARgF6gn/25K6zWy2mU2U9CNJmxvTFoBmq3moz91Pm9m9kv5LQ0N969z9/YZ1BqCp\n6hrnd/eXJb3coF4AtBAf7wWCIvxAUIQfCIrwA0ERfiAowg8E1dLv82NkR44cSdb37duXrL/00ksV\naw888EBy2+effz5ZX7p0abI+ZcqUZB3tiyM/EBThB4Ii/EBQhB8IivADQRF+ICiG+lpgz549yfrK\nlSuT9SeeeCJZX7169Xn3dM6KFStq3hajG0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf4GeOON\nN5L1Z599Nllfv359sn7ppZeed09AHo78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUXeP8ZtYn6TNJ\nZySddvdSI5oqQn9/f7K+du3airWNGzcmt82rM46PIjTiQz43uvuxBjwOgBbiZT8QVL3hd0l/NLOd\nZrasEQ0BaI16X/YvcPfDZvY3kl41sw/cvXf4CtkfhWWSNGvWrDp3B6BR6jryu/vh7PeApBclzR9h\nnR53L7l7qaOjo57dAWigmsNvZpPMbMq525K+J+m9RjUGoLnqedk/XdKLZnbucf7d3f+zIV0BaLqa\nw+/uH0v6uwb2UqgDBw4k61u3bq1YW7NmTXLb7u7uWloCmoqhPiAowg8ERfiBoAg/EBThB4Ii/EBQ\nXLo7c8011yTrr7/+eos6AVqDIz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4PwqTd7n0yy+/PFmf\nOHFiI9sJhyM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOP8YsHfv3oq106dPJ7d96623kvW+vr5k\n/bXXXqt5+8HBweS2eVOXd3Z2JutLly6tWFu+fHly2wsuGPvR4MgPBEX4gaAIPxAU4QeCIvxAUIQf\nCIrwA0GZu6dXMFsn6QeSBtx9TrbsMkm/l9QlqU/SInf/S97OSqWSl8vlOlsee3bs2JGsL1q0KFk/\ndOhQxdrZs2dr6umcG264IVmfOXNmXY+fsnv37rrqKSdOnEjWJ0+eXPNjF6lUKqlcLls161Zz5P+N\npFu+tmylpC3u3i1pS3YfwCiSG35375V0/GuLF0pan91eL+n2BvcFoMlqfc8/3d3PXYPpE0nTG9QP\ngBap+4SfD500qHjiwMyWmVnZzMp5n+UG0Dq1hv+omXVKUvZ7oNKK7t7j7iV3L3V0dNS4OwCNVmv4\nN0takt1eImlTY9oB0Cq54TezFyS9KelKMztkZkslPSnpu2b2kaR/yu4DGEVyv7Ts7osrlG5ucC9h\nzZkzJ1mfNWtWsn7ddddVrN1zzz3Jba+99tpkffz48cn6uHG1nzb68MMPk/U77rij5seWpMcee6xi\nbdKkSXU99ljAJ/yAoAg/EBThB4Ii/EBQhB8IivADQY396xOPAhdffHGy3tvbm6yfOXOmYm379u3J\nbd98881kPc8rr7ySrK9evbrmx877unl3d3ey/uCDD1asmVX1rdcxjSM/EBThB4Ii/EBQhB8IivAD\nQRF+ICjCDwTFOP8oMDBQ8UJJkqQFCxZUrKWm726FSy65pGItbxrsTz/9NFnP+7c99dRTFWv3339/\nctuLLrooWR8LOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM848CEyZMSNavvPLKirUvvvgiue3N\nN6evwD579uxk/c4770zWu7q6KtbyxtL379+frD/88MPJ+qpVq2p+7J6enmR9LFwPgCM/EBThB4Ii\n/EBQhB8IivADQRF+ICjCDwRleddGN7N1kn4gacDd52TLHpX0Y0mD2WoPufvLeTsrlUpeLpfrahg4\n59SpU8l66rr+Bw8eTG77+eefJ+vt+n3/Uqmkcrlc1YcQqjny/0bSLSMs/6W7z81+coMPoL3kht/d\neyUdb0EvAFqonvf895rZbjNbZ2ZTG9YRgJaoNfxrJH1b0lxJ/ZJ+UWlFM1tmZmUzKw8ODlZaDUCL\n1RR+dz/q7mfc/aykX0uan1i3x91L7l7q6OiotU8ADVZT+M2sc9jdH0p6rzHtAGiV3K/0mtkLkr4j\naZqZHZL0c0nfMbO5klxSn6TlTewRQBPkht/dF4+w+Lkm9AKcl4kTJybr7ToW3y74hB8QFOEHgiL8\nQFCEHwiK8ANBEX4gKC7djVHryy+/TNZTly1PTR0ujY1Lc+fhyA8ERfiBoAg/EBThB4Ii/EBQhB8I\nivADQTHOnzl79myy3tvbW7G2Y8eO5LZTpkxJ1u++++5kPW+K7rHqyJEjyfojjzySrB84cKBibe3a\ntcltL7zwwmR9LODIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc6f2bZtW7J+0003NW3fjz/+eLL+\n9NNPJ+vz5s2rWEtNUy1J48ePT9bz5I3FnzhxomJt06ZNyW1XrVqVrOd9n/+ZZ56pWMv7bEUEHPmB\noAg/EBThB4Ii/EBQhB8IivADQRF+IKjccX4zmylpg6TpklxSj7v/yswuk/R7SV2S+iQtcve/NK/V\n5rrqqquS9dSY8YYNG5Lb7tq1K1k/evRosn7XXXcl6ylTp05N1vOuT+/uyfrJkyeT9byx+JTbbrst\nWb/vvvuS9RtvvLFiLcJ1+fNUc+Q/Lemn7n61pH+Q9BMzu1rSSklb3L1b0pbsPoBRIjf87t7v7ruy\n259J2iNphqSFktZnq62XdHuzmgTQeOf1nt/MuiTNk7Rd0nR3789Kn2jobQGAUaLq8JvZZEl/kLTC\n3b/ygW0femM44ptDM1tmZmUzKw8ODtbVLIDGqSr8ZjZBQ8H/rbtvzBYfNbPOrN4paWCkbd29x91L\n7l7q6OhoRM8AGiA3/DZ0WvQ5SXvcffjXyzZLWpLdXiIp/RUtAG3F8oZyzGyBpP+V9K6kc9e3fkhD\n7/v/Q9IsSfs1NNR3PPVYpVLJy+VyvT23nbzLfvf39yfr+/btS9Z37tyZrH/wwQcVa1u3bk1ue8UV\nVyTrXV1dyXpqOE2SZsyYUbGW+iqyJE2ePDlZZ7jum0qlksrlclVPTO44v7tvk1TpwW4+n8YAtA8+\n4QcERfiBoAg/EBThB4Ii/EBQhB8Iikt3N8C4cem/oamx7mrq119//Xn3BOThyA8ERfiBoAg/EBTh\nB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU\n4QeCIvxAUIQfCIrwA0Hlht/MZprZ/5jZn83sfTO7L1v+qJkdNrN3sp9bm98ugEapZtKO05J+6u67\nzGyKpJ1m9mpW+6W7/2vz2gPQLLnhd/d+Sf3Z7c/MbI+k9BQzANreeb3nN7MuSfMkbc8W3Wtmu81s\nnZlNrbDNMjMrm1l5cHCwrmYBNE7V4TezyZL+IGmFu5+QtEbStyXN1dArg1+MtJ2797h7yd1LHR0d\nDWgZQCNUFX4zm6Ch4P/W3TdKkrsfdfcz7n5W0q8lzW9emwAarZqz/SbpOUl73P3pYcs7h632Q0nv\nNb49AM1Szdn+f5T0z5LeNbN3smUPSVpsZnMluaQ+Scub0iGApqjmbP82STZC6eXGtwOgVfiEHxAU\n4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IChz99btzGxQ0v5h\ni6ZJOtayBs5Pu/bWrn1J9FarRvZ2hbtXdb28lob/Gzs3K7t7qbAGEtq1t3btS6K3WhXVGy/7gaAI\nPxBU0eHvKXj/Ke3aW7v2JdFbrQrprdD3/ACKU/SRH0BBCgm/md1iZh+a2V4zW1lED5WYWZ+ZvZvN\nPFwuuJd1ZjZgZu8NW3aZmb1qZh9lv0ecJq2g3tpi5ubEzNKFPnftNuN1y1/2m9l4Sf8n6buSDkl6\nW9Jid/9zSxupwMz6JJXcvfAxYTO7XtJJSRvcfU627ClJx939yewP51R3f7BNentU0smiZ27OJpTp\nHD6ztKTbJf2LCnzuEn0tUgHPWxFH/vmS9rr7x+5+StLvJC0soI+25+69ko5/bfFCSeuz2+s19J+n\n5Sr01hbcvd/dd2W3P5N0bmbpQp+7RF+FKCL8MyQdHHb/kNprym+X9Ecz22lmy4puZgTTs2nTJekT\nSdOLbGYEuTM3t9LXZpZum+eulhmvG40Tft+0wN3/XtL3Jf0ke3nblnzoPVs7DddUNXNzq4wws/Rf\nFfnc1TrjdaMVEf7DkmYOu/+tbFlbcPfD2e8BSS+q/WYfPnpuktTs90DB/fxVO83cPNLM0mqD566d\nZrwuIvxvS+o2s9lmNlHSjyRtLqCPbzCzSdmJGJnZJEnfU/vNPrxZ0pLs9hJJmwrs5SvaZebmSjNL\nq+Dnru1mvHb3lv9IulVDZ/z3SfpZET1U6OtvJf0p+3m/6N4kvaChl4FfaujcyFJJl0vaIukjSf8t\n6bI26u15Se9K2q2hoHUW1NsCDb2k3y3pnezn1qKfu0RfhTxvfMIPCIoTfkBQhB8IivADQRF+ICjC\nDwRF+IGgCD8QFOEHgvp/efB9TwsBuz0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c158048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1),\n",
    "                              feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "print(\"Result: \", sess.run(tf.equal(sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)), sess.run(tf.argmax(hypothesis, 1),\n",
    "                              feed_dict={X: mnist.test.images[r:r+1]}))))\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN/Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "neurons = 100\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, neurons]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([neurons]), name='bias1')\n",
    "logits1 = tf.matmul(X, W1) + b1\n",
    "layer1 = tf.sigmoid(logits1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([neurons]), name='bias3')\n",
    "logits2 = tf.matmul(layer1, W2) + b2\n",
    "layer2 = tf.sigmoid(logits2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([neurons]), name='bias3')\n",
    "logits3 = tf.matmul(layer2, W3) + b3\n",
    "layer3 = tf.sigmoid(logits3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([neurons, nb_classes]), name='weight4')\n",
    "b4 = tf.Variable(tf.random_normal([nb_classes]), name='bias4')\n",
    "\n",
    "logits4 = tf.matmul(layer3, W4) + b4\n",
    "hypothesis = tf.nn.softmax(logits4)\n",
    "\n",
    "sig_W4_hist = tf.summary.histogram(\"W4\", W4)\n",
    "sig_b4_hist = tf.summary.histogram(\"b4\", b4)\n",
    "sig_hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits4, \n",
    "                                                labels=Y)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "sig_cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.3).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 \tcost =  1.001210188\n",
      "Epoch:  0011 \tcost =  0.211217490\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "sess = tf.Session()\n",
    "summary = tf.summary.merge([sig_W4_hist, sig_b4_hist, sig_hypothesis_hist, sig_cost_summ])\n",
    "train_writer = tf.summary.FileWriter('./logs/MNIST_sigDNN', sess.graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        s, c, _ = sess.run([summary, cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        train_writer.add_summary(s, global_step=global_step)\n",
    "        avg_cost += c / total_batch\n",
    "        global_step += 1\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: ', '%04d' % (epoch + 1), '\\tcost = ', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9282\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy.eval(session=sess,\n",
    "                                 feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [4]\n",
      "Prediction:  [4]\n",
      "Result:  [ True]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADC9JREFUeJzt3V+oHOd5x/HvUze5cXJhV1shHLsnDcbGGKqERRRiSoqa\n4JiAHBlMfBFUMFXAMiSQixr1or4ypjQJuZADSi2ilNRJ4chYF6aNKwomUIKPjes/8XHtmhMiIUtH\nOBDnKrXz9OKMwol8zu56d2Znj5/vB5YzO+/szuPBP83svDPzRmYiqZ4/6LsASf0w/FJRhl8qyvBL\nRRl+qSjDLxVl+KWiDL9UlOGXivrDea5s165dubS0NM9VSqWsra1x6dKlmGTZmcIfEbcD3wauAv4p\nMx8etfzS0hIrKyuzrFLSCMPhcOJlpz7sj4irgGPA54FbgHsi4pZpv0/SfM3ym38f8HpmvpGZvwF+\nCBxopyxJXZsl/NcBv9j0/mwz7/dExOGIWImIlfX19RlWJ6lNnZ/tz8zjmTnMzOFgMOh6dZImNEv4\nzwHXb3r/sWaepB1glvA/A9wYER+PiA8DXwJOt1OWpK5N3dWXme9ExP3Av7PR1XciM19urTJJnZqp\nnz8znwSebKkWSXPk5b1SUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjD\nLxU110d3q55XX31127abb7555GcPHjw4sn15eXmqmrTBPb9UlOGXijL8UlGGXyrK8EtFGX6pKMMv\nFWU/vzp10003Tf3ZU6dOtViJruSeXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKmqmfPyLWgLeBd4F3\nMnPYRlHSJEY9KwBmu8aggjYu8vnLzLzUwvdImiMP+6WiZg1/Aj+OiGcj4nAbBUmaj1kP+2/LzHMR\n8cfAUxGxmplPb16g+UfhMMANN9ww4+oktWWmPX9mnmv+XgQeB/ZtsczxzBxm5nAwGMyyOkktmjr8\nEXF1RHz08jTwOeCltgqT1K1ZDvt3A49HxOXv+ZfM/LdWqpLUuanDn5lvAH/WYi3S+2I//mzs6pOK\nMvxSUYZfKsrwS0UZfqkowy8V5aO7d4BHHnlkZPuRI0em/u7V1dWR7bN2p4277Vb9cc8vFWX4paIM\nv1SU4ZeKMvxSUYZfKsrwS0XZz78AxvWFz9KPP86ZM2dGts/azz/u+9Uf9/xSUYZfKsrwS0UZfqko\nwy8VZfilogy/VJT9/HPQ5f344xw8eHBk+/79+2f6/nHXKMzSzz+uds3GPb9UlOGXijL8UlGGXyrK\n8EtFGX6pKMMvFTW2nz8iTgBfAC5m5q3NvGuBHwFLwBpwd2b+srsyd7Yu+/FhdH/4Qw89NPKzXd+v\nf+rUqam/e9ZrEDTaJHv+7wG3XzHvAeBMZt4InGneS9pBxoY/M58G3rpi9gHgZDN9Eriz5bokdWza\n3/y7M/N8M/0msLuleiTNycwn/DIzgdyuPSIOR8RKRKysr6/PujpJLZk2/BciYg9A8/fidgtm5vHM\nHGbmcDAYTLk6SW2bNvyngUPN9CHgiXbKkTQvY8MfEY8B/wXcFBFnI+Je4GHgsxHxGvBXzXtJO8jY\nfv7MvGebJjthG32PQb+8vNzburvsi7efv1te4ScVZfilogy/VJThl4oy/FJRhl8qykd3t+Do0aOd\nfv/q6mqn3z+LWW8JVn/c80tFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUfbzT2jUbbuzPJ4axg9Fvch9\n6eOGH5/FIv93fxC455eKMvxSUYZfKsrwS0UZfqkowy8VZfilouznn1CX9+yPG0Z7kY0bortPo65B\nGFd3n49Dnxf3/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9U1Nh+/og4AXwBuJiZtzbzHgT+BlhvFjua\nmU92VeQimOWe/WPHjo1s38n3rc/6LINRxj0r4MiRI52tu4JJ9vzfA27fYv63MnNv8/pAB1/6IBob\n/sx8GnhrDrVImqNZfvPfHxEvRMSJiLimtYokzcW04f8O8AlgL3Ae+MZ2C0bE4YhYiYiV9fX17RaT\nNGdThT8zL2Tmu5n5W+C7wL4Ryx7PzGFmDgeDwbR1SmrZVOGPiD2b3n4ReKmdciTNyyRdfY8BnwF2\nRcRZ4O+Bz0TEXiCBNeArHdYoqQNjw5+Z92wx+9EOavnAWuR73sfps/Yu+/HHjZVQgVf4SUUZfqko\nwy8VZfilogy/VJThl4ry0d1zMO621y5vi93JxnXH7d+/f+r2nXwbdVvc80tFGX6pKMMvFWX4paIM\nv1SU4ZeKMvxSUfbzT2h1dXXbtnHDd1fuxx/VVz9uaHL74rvlnl8qyvBLRRl+qSjDLxVl+KWiDL9U\nlOGXirKff0Kj+pyXl5fnWEm77rrrrpHtXV6jYD9+v9zzS0UZfqkowy8VZfilogy/VJThl4oy/FJR\nY/v5I+J64PvAbiCB45n57Yi4FvgRsASsAXdn5i+7K1Vd6PNZA+OuMRhnJ19fsQgm2fO/A3w9M28B\n/hw4EhG3AA8AZzLzRuBM817SDjE2/Jl5PjOfa6bfBl4BrgMOACebxU4Cd3ZVpKT2va/f/BGxBHwS\n+CmwOzPPN01vsvGzQNIOMXH4I+IjwDLwtcz81ea2zEw2zgds9bnDEbESESvr6+szFSupPROFPyI+\nxEbwf5CZl88QXYiIPU37HuDiVp/NzOOZOczM4WAwaKNmSS0YG/6ICOBR4JXM/OamptPAoWb6EPBE\n++VJ6sokt/R+Gvgy8GJEPN/MOwo8DPxrRNwL/By4u5sStZNVfmz5ohsb/sz8CRDbNI8eIF3SwvIK\nP6kowy8VZfilogy/VJThl4oy/FJRPrq7uFFDaEO3/fTHjh0b2X7fffd1tm6555fKMvxSUYZfKsrw\nS0UZfqkowy8VZfilouznL87HX9flnl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtF\nGX6pKMMvFWX4paIMv1SU4ZeKGhv+iLg+Iv4zIn4WES9HxFeb+Q9GxLmIeL553dF9uZLaMsnDPN4B\nvp6Zz0XER4FnI+Kppu1bmfmP3ZUnqStjw5+Z54HzzfTbEfEKcF3XhUnq1vv6zR8RS8AngZ82s+6P\niBci4kREXLPNZw5HxEpErKyvr89UrKT2TBz+iPgIsAx8LTN/BXwH+ASwl40jg29s9bnMPJ6Zw8wc\nDgaDFkqW1IaJwh8RH2Ij+D/IzFMAmXkhM9/NzN8C3wX2dVempLZNcrY/gEeBVzLzm5vm79m02BeB\nl9ovT1JXJjnb/2ngy8CLEfF8M+8ocE9E7AUSWAO+0kmFkjoxydn+nwCxRdOT7ZcjaV68wk8qyvBL\nRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1RUZOb8VhaxDvx806xd\nwKW5FfD+LGpti1oXWNu02qztTzJzouflzTX871l5xEpmDnsrYIRFrW1R6wJrm1ZftXnYLxVl+KWi\n+g7/8Z7XP8qi1raodYG1TauX2nr9zS+pP33v+SX1pJfwR8TtEfFqRLweEQ/0UcN2ImItIl5sRh5e\n6bmWExFxMSJe2jTv2oh4KiJea/5uOUxaT7UtxMjNI0aW7nXbLdqI13M/7I+Iq4D/AT4LnAWeAe7J\nzJ/NtZBtRMQaMMzM3vuEI+IvgF8D38/MW5t5/wC8lZkPN/9wXpOZf7sgtT0I/LrvkZubAWX2bB5Z\nGrgT+Gt63HYj6rqbHrZbH3v+fcDrmflGZv4G+CFwoIc6Fl5mPg28dcXsA8DJZvokG//zzN02tS2E\nzDyfmc81028Dl0eW7nXbjairF32E/zrgF5ven2WxhvxO4McR8WxEHO67mC3sboZNB3gT2N1nMVsY\nO3LzPF0xsvTCbLtpRrxumyf83uu2zPwU8HngSHN4u5By4zfbInXXTDRy87xsMbL07/S57aYd8bpt\nfYT/HHD9pvcfa+YthMw81/y9CDzO4o0+fOHyIKnN34s91/M7izRy81YjS7MA226RRrzuI/zPADdG\nxMcj4sPAl4DTPdTxHhFxdXMihoi4Gvgcizf68GngUDN9CHiix1p+z6KM3LzdyNL0vO0WbsTrzJz7\nC7iDjTP+/wv8XR81bFPXnwL/3bxe7rs24DE2DgP/j41zI/cCfwScAV4D/gO4doFq+2fgReAFNoK2\np6fabmPjkP4F4PnmdUff225EXb1sN6/wk4ryhJ9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paL+\nH2oU7J9Ffn4MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a825780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1),\n",
    "                              feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "print(\"Result: \", sess.run(tf.equal(sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)), sess.run(tf.argmax(hypothesis, 1),\n",
    "                              feed_dict={X: mnist.test.images[r:r+1]}))))\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN/ReLU - fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "neurons = 100\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, neurons]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([neurons]), name='bias1')\n",
    "logits1 = tf.matmul(X, W1) + b1\n",
    "layer1 = tf.nn.relu(logits1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([neurons]), name='bias3')\n",
    "logits2 = tf.matmul(layer1, W2) + b2\n",
    "layer2 = tf.nn.relu(logits2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([neurons]), name='bias3')\n",
    "logits3 = tf.matmul(layer2, W3) + b3\n",
    "layer3 = tf.nn.relu(logits3)\n",
    "\n",
    "\n",
    "#W4 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight4')\n",
    "W4 = tf.Variable(tf.random_normal([neurons, nb_classes]), name='weight4')\n",
    "#b4 = tf.Variable(tf.random_normal([neurons]), name='bias4')\n",
    "b4 = tf.Variable(tf.random_normal([nb_classes]), name='bias4')\n",
    "logits4 = tf.matmul(layer3, W4) + b4\n",
    "#layer4 = tf.nn.relu(logits4)\n",
    "hypothesis = logits4\n",
    "'''\n",
    "W5 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight5')\n",
    "b5 = tf.Variable(tf.random_normal([neurons]), name='bias5')\n",
    "logits5 = tf.matmul(layer4, W5) + b5\n",
    "layer5 = tf.nn.relu(logits5)\n",
    "\n",
    "W6 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight6')\n",
    "b6 = tf.Variable(tf.random_normal([neurons]), name='bias6')\n",
    "logits6 = tf.matmul(layer4, W5) + b5\n",
    "layer6 = tf.nn.relu(logits5)\n",
    "\n",
    "W7 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight7')\n",
    "b7 = tf.Variable(tf.random_normal([neurons]), name='bias7')\n",
    "logits7 = tf.matmul(layer5, W6) + b6\n",
    "layer7 = tf.nn.relu(logits6)\n",
    "\n",
    "W8 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight8')\n",
    "b8 = tf.Variable(tf.random_normal([neurons]), name='bias8')\n",
    "logits8 = tf.matmul(layer6, W7) + b7\n",
    "layer8 = tf.nn.relu(logits7)\n",
    "\n",
    "W9 = tf.Variable(tf.random_normal([neurons, neurons]), name='weight9')\n",
    "b9 = tf.Variable(tf.random_normal([neurons]), name='bias9')\n",
    "logits9 = tf.matmul(layer8, W9) + b9\n",
    "layer9 = tf.nn.relu(logits9)\n",
    "\n",
    "W10 = tf.Variable(tf.random_normal([neurons, nb_classes]), name='weight10')\n",
    "b10 = tf.Variable(tf.random_normal([nb_classes]), name='bias10')\n",
    "logits10 = tf.matmul(layer9, W10) + b10\n",
    "hypothesis = logits10\n",
    "'''\n",
    "\n",
    "\n",
    "#relu_W4_hist = tf.summary.histogram(\"W4\", W4)\n",
    "#relu_b4_hist = tf.summary.histogram(\"b4\", b4)\n",
    "#relu_hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, \n",
    "                                                labels=Y)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "relu_cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 \tcost =  81.246773287\n",
      "Epoch:  0011 \tcost =  0.729211349\n",
      "Epoch:  0021 \tcost =  1.908647899\n",
      "Epoch:  0031 \tcost =  1.848427754\n",
      "Epoch:  0041 \tcost =  1.847590165\n",
      "Epoch:  0051 \tcost =  1.845671417\n",
      "Epoch:  0061 \tcost =  1.845008698\n",
      "Epoch:  0071 \tcost =  1.847287672\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 150\n",
    "batch_size = 100\n",
    "\n",
    "sess = tf.Session()\n",
    "summary = tf.summary.merge([relu_cost_summ])\n",
    "train_writer = tf.summary.FileWriter('./logs/MNIST_reluDNN', sess.graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        s, c, _ = sess.run([summary, cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        train_writer.add_summary(s, global_step=global_step)\n",
    "        avg_cost += c / total_batch\n",
    "        global_step += 1\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: ', '%04d' % (epoch + 1), '\\tcost = ', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", accuracy.eval(session=sess,\n",
    "                                 feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1),\n",
    "                              feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "print(\"Result: \", sess.run(tf.equal(sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)), sess.run(tf.argmax(hypothesis, 1),\n",
    "                              feed_dict={X: mnist.test.images[r:r+1]}))))\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
